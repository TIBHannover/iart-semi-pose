{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fb82e837-10c2-4aa3-bdef-1c26d32052a4",
      "metadata": {
        "id": "fb82e837-10c2-4aa3-bdef-1c26d32052a4"
      },
      "source": [
        "# Example of the prediction of the semi-supervised pose model for art\n",
        "\n",
        "## Loading of dependencies and definition of auxiliary functions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a45a5716-d1f5-422b-869c-ef58d1fe76f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a45a5716-d1f5-422b-869c-ef58d1fe76f7",
        "outputId": "bc89a13c-7b03-4fed-989b-0a1b31d01974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.7/dist-packages (0.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface_hub) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2022.9.24)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub;\n",
        "import numpy as np\n",
        "import torch\n",
        "from huggingface_hub import hf_hub_url, cached_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c7f1fed8-d769-4aa8-960c-09ef6a737dad",
      "metadata": {
        "id": "c7f1fed8-d769-4aa8-960c-09ef6a737dad"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def box_cxcywh_to_xyxy(x):\n",
        "    x_c, y_c, w, h = x.unbind(-1)\n",
        "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h), (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
        "    return torch.stack(b, dim=-1)\n",
        "\n",
        "\n",
        "def box_xyxy_to_cxcywh(x):\n",
        "    x0, y0, x1, y1 = x.unbind(-1)\n",
        "    b = [(x0 + x1) / 2, (y0 + y1) / 2, (x1 - x0), (y1 - y0)]\n",
        "    return torch.stack(b, dim=-1)\n",
        "\n",
        "\n",
        "def box_xyxy_to_4points(x):\n",
        "    x0, y0, x1, y1 = x.unbind(-1)\n",
        "    b = [x0, y0, x1, y1, x0, y1, x1, y0]\n",
        "    return torch.stack(b, dim=-1)\n",
        "\n",
        "\n",
        "def box_4points_to_xyxy(x):\n",
        "    x0, y0, x1, y1, x2, y2, x3, y3 = x.unbind(-1)\n",
        "    xs = torch.stack([x0, x1, x2, x3], dim=-1)\n",
        "    ys = torch.stack([y0, y1, y2, y3], dim=-1)\n",
        "\n",
        "    b = [\n",
        "        torch.min(xs, dim=-1).values,\n",
        "        torch.min(ys, dim=-1).values,\n",
        "        torch.max(xs, dim=-1).values,\n",
        "        torch.max(ys, dim=-1).values,\n",
        "    ]\n",
        "    return torch.stack(b, dim=-1)\n",
        "\n",
        "\n",
        "def point_to_abs(points, size):\n",
        "\n",
        "    original_shape = points.shape\n",
        "    points = points.reshape(-1, original_shape[-1])\n",
        "    points, meta = points[:, :2], points[:, 2:]\n",
        "    points = points * torch.as_tensor([size[1], size[0]], device=points.device)\n",
        "\n",
        "    transformed_points = torch.cat([points, meta], dim=-1)\n",
        "    return transformed_points.reshape(original_shape)\n",
        "\n",
        "\n",
        "def point_to_rel(points, size):\n",
        "\n",
        "    original_shape = points.shape\n",
        "    points = points.reshape(-1, original_shape[-1])\n",
        "    points, meta = points[:, :2], points[:, 2:]\n",
        "    points = points / torch.as_tensor([size[1], size[0]], device=points.device)\n",
        "\n",
        "    transformed_points = torch.cat([points, meta], dim=-1)\n",
        "    return transformed_points.reshape(original_shape)\n",
        "\n",
        "\n",
        "def points_transformation(points, transformation):\n",
        "    original_shape = points.shape\n",
        "\n",
        "    # prepare points [N,3]\n",
        "    points = points.reshape(-1, original_shape[-1])\n",
        "    points, meta = points[:, :2], points[:, 2:]\n",
        "    points = torch.cat([points, torch.as_tensor([[1.0]] * points.shape[0], device=points.device)], dim=1)\n",
        "    points = points.unsqueeze(2)\n",
        "\n",
        "    # prepare transformation [N,3,3]\n",
        "    if len(transformation.shape) == 2:\n",
        "        transformation = torch.unsqueeze(transformation, dim=0).expand(points.shape[0], 3, 3)\n",
        "\n",
        "    transformed_points = transformation @ points\n",
        "    transformed_points = torch.cat([torch.squeeze(transformed_points, 2)[:, :2], meta], dim=-1)\n",
        "    return transformed_points.reshape(original_shape)\n",
        "\n",
        "\n",
        "def boxes_to_abs(boxes, size):\n",
        "\n",
        "    original_shape = boxes.shape\n",
        "    boxes = boxes.reshape(-1, original_shape[-1])\n",
        "    boxes, meta = boxes[:, :4], boxes[:, 4:]\n",
        "    boxes = boxes * torch.as_tensor([size[1], size[0], size[1], size[0]], device=boxes.device)\n",
        "\n",
        "    transformed_boxes = torch.cat([boxes, meta], dim=-1)\n",
        "    return transformed_boxes.reshape(original_shape)\n",
        "\n",
        "\n",
        "def boxes_to_rel(boxes, size):\n",
        "\n",
        "    original_shape = boxes.shape\n",
        "    boxes = boxes.reshape(-1, original_shape[-1])\n",
        "    boxes, meta = boxes[:, :4], boxes[:, 4:]\n",
        "    boxes = boxes / torch.as_tensor([size[1], size[0], size[1], size[0]], device=boxes.device)\n",
        "\n",
        "    transformed_boxes = torch.cat([boxes, meta], dim=-1)\n",
        "    return transformed_boxes.reshape(original_shape)\n",
        "\n",
        "\n",
        "def boxes_transformation(boxes, transformation):\n",
        "    original_shape = boxes.shape\n",
        "\n",
        "    # prepare points [N,3]\n",
        "    points = boxes.reshape(-1, original_shape[-1])\n",
        "    # should be possible with a single reshape\n",
        "    points_xyxy, meta = points[:, :4], points[:, 4:]\n",
        "    # we need to compute all 4 points\n",
        "\n",
        "    points = box_xyxy_to_4points(points_xyxy)\n",
        "    points = points.reshape(-1, 2)\n",
        "    transformed_points = points_transformation(points, transformation)\n",
        "    transformed_points = transformed_points.reshape(-1, 8)\n",
        "\n",
        "    transformed_points = box_4points_to_xyxy(transformed_points)\n",
        "\n",
        "    transformed_points = torch.cat([transformed_points, meta], dim=-1)\n",
        "    return transformed_points.reshape(original_shape)\n",
        "\n",
        "\n",
        "def boxes_fit_size(boxes, size):\n",
        "    h, w = size[0], size[1]\n",
        "\n",
        "    original_shape = boxes.shape\n",
        "\n",
        "    max_size = torch.as_tensor([w, h], dtype=torch.float32, device=size.device)\n",
        "    boxes = torch.min(boxes.reshape(-1, 2, 2), max_size)\n",
        "    boxes = boxes.clamp(min=0)\n",
        "\n",
        "    return boxes.reshape(original_shape)\n",
        "\n",
        "\n",
        "def boxes_scale(boxes, scale, size=None):\n",
        "\n",
        "    box_cxcywh = box_xyxy_to_cxcywh(boxes)\n",
        "    scaled_box_wh = box_cxcywh[2:] * scale\n",
        "    scaled_box = box_cxcywh_to_xyxy(torch.cat([box_cxcywh[:2], scaled_box_wh], dim=0))\n",
        "    if size is not None:\n",
        "        scaled_box = boxes_fit_size(scaled_box, size)\n",
        "\n",
        "    return scaled_box\n",
        "\n",
        "\n",
        "def boxes_aspect_ratio(boxes, aspect_ratio, size=None):\n",
        "    box_cxcywh = box_xyxy_to_cxcywh(boxes)\n",
        "    w, h = box_cxcywh[2], box_cxcywh[3]\n",
        "    n_w, n_h = w, h\n",
        "    if w > aspect_ratio * h:\n",
        "        n_h = w * 1.0 / aspect_ratio\n",
        "    elif w < aspect_ratio * h:\n",
        "        n_w = h * aspect_ratio\n",
        "    scaled_box = box_cxcywh_to_xyxy(torch.stack([box_cxcywh[0], box_cxcywh[1], n_w, n_h], dim=0))\n",
        "    if size is not None:\n",
        "        scaled_box = boxes_fit_size(scaled_box, size)\n",
        "    return scaled_box\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Person detection"
      ],
      "metadata": {
        "id": "SMI23csN3WNI"
      },
      "id": "SMI23csN3WNI"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7116d27c-8d2a-4d79-a50e-95ca4af8eae8",
      "metadata": {
        "id": "7116d27c-8d2a-4d79-a50e-95ca4af8eae8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def post_process_person_predictions(pred_logits, pred_boxes, targets, threshold=0.1):\n",
        "\n",
        "    predictions = {\"boxes\": [], \"labels\": [], \"size\": targets[\"size\"], \"scores\": []}\n",
        "\n",
        "    batch_size = pred_logits.shape[0]\n",
        "\n",
        "    label_softmax = torch.softmax(pred_logits, dim=-1)\n",
        "    top_prediction = label_softmax > threshold\n",
        "    boxes_pos = top_prediction[..., :-1].nonzero()\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        scores = []\n",
        "        inv_transformation = torch.linalg.inv(targets[\"transformation\"][b])\n",
        "        weak_boxes_abs = boxes_to_abs(box_cxcywh_to_xyxy(pred_boxes[b]), size=targets[\"size\"][b])\n",
        "        boxes_origins_abs = boxes_transformation(weak_boxes_abs, inv_transformation)\n",
        "\n",
        "        boxes_sample = boxes_pos[boxes_pos[:, 0] == b]\n",
        "\n",
        "        for box in boxes_sample.unbind(0):\n",
        "            box_index = box[1]\n",
        "            box_cls = box[2]\n",
        "            box_cxcywh = boxes_origins_abs[box_index]\n",
        "            box_score = label_softmax[b, box_index, box_cls]\n",
        "            labels.append(box_cls)\n",
        "            boxes.append(box_cxcywh)\n",
        "            scores.append(box_score)\n",
        "        if len(boxes) > 0:\n",
        "            predictions[\"boxes\"].append(torch.stack(boxes, dim=0))\n",
        "            predictions[\"labels\"].append(torch.stack(labels, dim=0))\n",
        "            predictions[\"scores\"].append(torch.stack(scores, dim=0))\n",
        "        else:\n",
        "            predictions[\"boxes\"].append(\n",
        "                torch.zeros(\n",
        "                    [0, 4],\n",
        "                    device=label_softmax.device,\n",
        "                )\n",
        "            )\n",
        "            predictions[\"labels\"].append(torch.zeros([0], dtype=torch.int64, device=label_softmax.device))\n",
        "            predictions[\"scores\"].append(torch.zeros([0], device=label_softmax.device))\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "REPO_ID = \"springsteinm/iart-semi-pose\"\n",
        "FILENAME = \"popart_semi_bbox_v1_trace.pt\"\n",
        "\n",
        "person_model = torch.jit.load(cached_download(hf_hub_url(REPO_ID, FILENAME)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "6e2c307a6c4b4aeaa3bd8a3ddc75e70d",
            "f3f8310d169a4be7957560f55af4c396",
            "93e9a4bfb94a477dad9737a152c7cdac",
            "5ac9170adfdf4e3da6d9537130da44ad",
            "a9d5fcc190eb4db99a6389d062f847c1",
            "d455a873432c4082a66d3efa9d081699",
            "b199457e55c5464a8bfac6fe61e5aa23",
            "6a60cbdfd4804eb38c47fd6049027f8f",
            "0fa2c5573d8c482b818aa634bb5a1b44",
            "02db444762a34acfb90fceaef7260cf8",
            "e5b74f917a8c41c1af507d79b0c4daef"
          ]
        },
        "id": "2aZezt-aTm-r",
        "outputId": "55c02e5d-54cf-4190-fa25-4593559029db"
      },
      "id": "2aZezt-aTm-r",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/file_download.py:591: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/334M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e2c307a6c4b4aeaa3bd8a3ddc75e70d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f1a558b3-891b-4ca5-bc15-6385319576e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "f1a558b3-891b-4ca5-bc15-6385319576e4",
        "outputId": "6b6b4792-14fe-422e-f3ef-dc0fdada54e2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3d3e6e55474f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexample_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./benjamin-west_mrs-thomas-keyes-and-her-daughter.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Create request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# Get format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/content/benjamin-west_mrs-thomas-keyes-and-her-daughter.jpg'"
          ]
        }
      ],
      "source": [
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "example_image = \"./benjamin-west_mrs-thomas-keyes-and-her-daughter.jpg\"\n",
        "\n",
        "image = imageio.imread(example_image)\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17f70cc9-bbf4-43d3-8737-850f931b0db6",
      "metadata": {
        "id": "17f70cc9-bbf4-43d3-8737-850f931b0db6"
      },
      "outputs": [],
      "source": [
        "prediction = person_model(torch.from_numpy(image))\n",
        "\n",
        "# targets describes the change of the image before it was given into the model, here everything is left on default.\n",
        "targets = {\n",
        "    \"size\": [image.shape[0:2]],\n",
        "    \"origin_size\": [image.shape[0:2]],\n",
        "    \"transformation\": [torch.tensor([[1.0, 0.0, 0.0000], [0.0000, 1.0, 0.0000], [0.0000, 0.0, 1.0000]])],\n",
        "}\n",
        "final_person_prediciton = post_process_person_predictions(prediction[0], prediction[1], targets=targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1c4a48-6834-4185-b472-f03dfd1f01c1",
      "metadata": {
        "id": "6a1c4a48-6834-4185-b472-f03dfd1f01c1"
      },
      "outputs": [],
      "source": [
        "cropped_images = []\n",
        "for box in final_person_prediciton[\"boxes\"][0]:\n",
        "  xyxy = box_cxcywh_to_xyxy(box).detach().numpy()\n",
        "  box_image = image[max(0,int(box[1])):int(box[3]),max(0,int(box[0])):int(box[2]),:]\n",
        "  fig, axs = plt.subplots(1, 1)\n",
        "  axs.imshow(box_image)\n",
        "  cropped_images.append(box_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37c0d9f1-bee7-4936-9d4c-a98b84ae431f",
      "metadata": {
        "id": "37c0d9f1-bee7-4936-9d4c-a98b84ae431f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1844a729-0895-4792-993f-71276a5899da",
      "metadata": {
        "id": "1844a729-0895-4792-993f-71276a5899da"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eb1f27a-cee8-49b1-881c-86b2a99082d5",
      "metadata": {
        "id": "6eb1f27a-cee8-49b1-881c-86b2a99082d5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a17e37b8-f387-4ec6-b06e-f38a10ab8455",
      "metadata": {
        "id": "a17e37b8-f387-4ec6-b06e-f38a10ab8455"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e2c307a6c4b4aeaa3bd8a3ddc75e70d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3f8310d169a4be7957560f55af4c396",
              "IPY_MODEL_93e9a4bfb94a477dad9737a152c7cdac",
              "IPY_MODEL_5ac9170adfdf4e3da6d9537130da44ad"
            ],
            "layout": "IPY_MODEL_a9d5fcc190eb4db99a6389d062f847c1"
          }
        },
        "f3f8310d169a4be7957560f55af4c396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d455a873432c4082a66d3efa9d081699",
            "placeholder": "​",
            "style": "IPY_MODEL_b199457e55c5464a8bfac6fe61e5aa23",
            "value": "Downloading: 100%"
          }
        },
        "93e9a4bfb94a477dad9737a152c7cdac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a60cbdfd4804eb38c47fd6049027f8f",
            "max": 334071254,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fa2c5573d8c482b818aa634bb5a1b44",
            "value": 334071254
          }
        },
        "5ac9170adfdf4e3da6d9537130da44ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02db444762a34acfb90fceaef7260cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_e5b74f917a8c41c1af507d79b0c4daef",
            "value": " 334M/334M [00:12&lt;00:00, 16.0MB/s]"
          }
        },
        "a9d5fcc190eb4db99a6389d062f847c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d455a873432c4082a66d3efa9d081699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b199457e55c5464a8bfac6fe61e5aa23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a60cbdfd4804eb38c47fd6049027f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa2c5573d8c482b818aa634bb5a1b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02db444762a34acfb90fceaef7260cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b74f917a8c41c1af507d79b0c4daef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}